{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.3230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.36851466e-08, 5.27673097e-07, 5.04441602e-09, 2.84088013e-07,\n",
       "       9.90970883e-05, 2.74789234e-04, 3.35479752e-06, 1.35858508e-07,\n",
       "       2.32727153e-06, 9.99616593e-01, 1.27358899e-06, 1.37984909e-06,\n",
       "       8.57815991e-15, 1.74892752e-12, 1.96603850e-07, 1.98633971e-09,\n",
       "       5.47386492e-10, 3.72095370e-15])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing DATA\n",
    "data1 = pd.read_csv(\"PROsMLmodels1/Data_40Grouping/data_exercise_40.csv\", usecols = range(1,120), header = 0)\n",
    "data1.fillna(data1.mean(), inplace = True)\n",
    "s1 = pd.read_csv('PROsMLmodels1/Data_40Grouping/data_exercise_40.csv', usecols = range(120,121) , header = 0)\n",
    "\n",
    "#Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data1, s1)\n",
    "\n",
    "#Fit Estimator\n",
    "est = GradientBoostingClassifier(n_estimators = 400, max_depth = 10)\n",
    "est.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Predict Class Labels\n",
    "pred = est.predict(X_test)\n",
    "\n",
    "#Score on test data\n",
    "acc = est.score(X_test, y_test)\n",
    "print('ACC: %.4f' % acc)\n",
    "\n",
    "# predict class probabilities\n",
    "est.predict_proba(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameter Tuning\n",
    "param_grid = {'learning_rate': [0.1, 0.01, 0.001],\n",
    "              'max_depth': [3, 10],\n",
    "              'min_samples_leaf': [3, 5, 7, 10],  \n",
    "              'max_features': [1.0, 0.3, 0.1] \n",
    "              }\n",
    "\n",
    "est = GradientBoostingRegressor(n_estimators=3000)\n",
    "gs_cv = GridSearchCV(est, param_grid).fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#Best hyperparameter setting\n",
    "print('Best hyperparameters: %r' % gs_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit model on best parameters\n",
    "est.set_params(**gs_cv.best_params_)\n",
    "est.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training0.990159\n",
      "\n",
      "accuracy on test0.303279\n",
      "\n",
      "accuracy on training set: 0.457080\n",
      "\n",
      "accuracy on test set: 0.257377\n",
      "\n",
      "accuracy on training set: 0.447786\n",
      "\n",
      "accuracy on test set: 0.272131\n"
     ]
    }
   ],
   "source": [
    "gbrt=GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train,y_train.values.ravel())\n",
    "print(\"accuracy on training: %f\" % gbrt.score(X_train,y_train.values.ravel()))\n",
    "print('\\n'\"accuracy on test: %f\" % gbrt.score(X_test,y_test))\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train.values.ravel())\n",
    "print('\\n'\"accuracy on training set: %f\" % gbrt.score(X_train, y_train.values.ravel()))\n",
    "print('\\n'\"accuracy on test set: %f\" % gbrt.score(X_test, y_test))\n",
    "\n",
    " \n",
    "gbrt = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\n",
    "gbrt.fit(X_train, y_train.values.ravel())\n",
    "print('\\n'\"accuracy on training set: %f\" % gbrt.score(X_train, y_train.values.ravel()))\n",
    "print('\\n'\"accuracy on test set: %f\" % gbrt.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5451215341121071"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regression Test\n",
    "reg = GradientBoostingRegressor(random_state=0)\n",
    "reg.fit(X_train, y_train.values.ravel())\n",
    "GradientBoostingRegressor(random_state=0)\n",
    "reg.predict(X_test[1:2])\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(criterion='mse', learning_rate=1, n_estimators=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training GBR Model\n",
    "params = {'n_estimators': 3, 'max_depth': 3, 'learning_rate': 1, 'criterion': 'mse'}\n",
    "gradient_boosting_regressor_model = GradientBoostingRegressor(**params)\n",
    "gradient_boosting_regressor_model.fit(data1, s1.values.ravel())\n",
    "\n",
    "#Evaluating the Model (x, y size needs to be adjusted)\n",
    "#plt.figure(figsize = (12,6))\n",
    "#plt.scatter(data1, s1.values.ravel())\n",
    "#plt.plot(data1, gradient_boosting_regressor_model.predict(data1), color = 'black')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.82      0.63       130\n",
      "         5.0       0.22      0.31      0.26        51\n",
      "        10.0       0.14      0.05      0.08        19\n",
      "        15.0       0.22      0.21      0.22        67\n",
      "        20.0       0.22      0.10      0.14        39\n",
      "        25.0       0.20      0.16      0.18        37\n",
      "        30.0       0.29      0.32      0.31        59\n",
      "        35.0       0.14      0.06      0.09        16\n",
      "        40.0       0.11      0.12      0.12        24\n",
      "        45.0       0.00      0.00      0.00        22\n",
      "        50.0       0.29      0.24      0.26        42\n",
      "        55.0       0.12      0.05      0.07        21\n",
      "        60.0       0.00      0.00      0.00        11\n",
      "        65.0       0.22      0.17      0.19        12\n",
      "        75.0       0.34      0.48      0.40        25\n",
      "        85.0       0.11      0.09      0.10        11\n",
      "       100.0       0.40      0.20      0.27        10\n",
      "       116.0       0.25      0.07      0.11        14\n",
      "\n",
      "    accuracy                           0.33       610\n",
      "   macro avg       0.21      0.19      0.19       610\n",
      "weighted avg       0.28      0.33      0.29       610\n",
      "\n",
      "Accuracy: 0.3262295081967213\n",
      "Precision: [0.51707317 0.22222222 0.14285714 0.22222222 0.22222222 0.2\n",
      " 0.29230769 0.14285714 0.11111111 0.         0.28571429 0.125\n",
      " 0.         0.22222222 0.34285714 0.11111111 0.4        0.25      ]\n",
      "Recall: [0.81538462 0.31372549 0.05263158 0.20895522 0.1025641  0.16216216\n",
      " 0.3220339  0.0625     0.125      0.         0.23809524 0.04761905\n",
      " 0.         0.16666667 0.48       0.09090909 0.2        0.07142857]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "y_pred = est.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#Model Accuracy\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "#Model Precision\n",
    "print('Precision:', metrics.precision_score(y_test, y_pred, average = None))\n",
    "#Model Recall\n",
    "print('Recall:', metrics.recall_score(y_test, y_pred,  average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
